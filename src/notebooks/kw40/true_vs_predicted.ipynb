{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "**Picture Naming - bias analyses**\n",
    "\n",
    "different plots for true vs. predicted scores\n",
    "- predicted vs. actual score (gender two colors, country two colors)\n",
    "- predicted vs. actual score with distributions; male, female, uk, us\n",
    "- errors sorted from highest to lowest with demographic information"
   ],
   "id": "244266b67da7be9c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T18:12:49.898586Z",
     "start_time": "2025-09-30T18:12:46.002278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "sns.set_theme(context=\"paper\", style=\"white\")\n",
    "\n",
    "# paths / settings \n",
    "OOF_PATH = \"/Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/results/regression/oof_results/oof_preds_all_scores.csv\"\n",
    "SAVE_DIR = \"/Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/results/regression/bias/plots\"\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "TARGET = \"PictureNamingScore\"\n",
    "TASK   = \"picnicScene\"\n",
    "MODEL  = \"full\"\n",
    "score   = \"Picture Naming Score\"\n",
    "\n",
    "gender_colors  = {\"f\": \"tomato\", \"m\": \"royalblue\"}\n",
    "country_colors = {\"uk\": \"tomato\", \"usa\": \"royalblue\"}\n",
    "\n",
    "# load OOF \n",
    "oof = pd.read_csv(OOF_PATH)\n",
    "\n",
    "# subject id\n",
    "if \"Subject_ID\" in oof.columns:\n",
    "    oof = oof.rename(columns={\"Subject_ID\":\"subject\"})\n",
    "elif \"subject\" not in oof.columns:\n",
    "    raise KeyError(f\"No subject id column found. OOF columns: {list(oof.columns)}\")\n",
    "\n",
    "# filter to subset\n",
    "need = [\"subject\",\"target\",\"model\",\"y_true\",\"y_pred\",\"task\"]\n",
    "for c in need:\n",
    "    if c not in oof.columns:\n",
    "        raise KeyError(f\"Column '{c}' missing in OOF file.\")\n",
    "sub = oof.loc[\n",
    "    (oof[\"target\"] == TARGET) &\n",
    "    (oof[\"model\"]  == MODEL)  &\n",
    "    (oof[\"task\"]   == TASK),\n",
    "    :\n",
    "].copy()\n",
    "\n",
    "# use label columns directly \n",
    "# Expect exactly \"Gender_label\" in {'f','m'} and \"Country_label\" in {'uk','usa'}\n",
    "if \"Gender_label\" not in sub.columns or \"Country_label\" not in sub.columns:\n",
    "    raise KeyError(\"Expected 'Gender_label' and 'Country_label' in the OOF file.\")\n",
    "\n",
    "sub[\"Gender\"]  = sub[\"Gender_label\"].astype(str).str.strip().str.lower()\n",
    "sub[\"Country\"] = sub[\"Country_label\"].astype(str).str.strip().str.lower()\n",
    "\n",
    "# keep only the two valid levels (single filter is enough)\n",
    "sub = sub[sub[\"Gender\"].isin([\"f\",\"m\"]) & sub[\"Country\"].isin([\"uk\",\"usa\"])]\n",
    "\n",
    "\n",
    "# (1) error CSV\n",
    "sub[\"error\"]     = sub[\"y_pred\"] - sub[\"y_true\"]\n",
    "sub[\"abs_error\"] = sub[\"error\"].abs()\n",
    "err_cols = [\"subject\",\"y_true\",\"y_pred\",\"error\",\"Gender\",\"Country\"]\n",
    "err_sorted = sub.sort_values(\"abs_error\", ascending=False)[err_cols]\n",
    "err_csv = os.path.join(SAVE_DIR, f\"{TARGET}_errors_sorted_{TASK}_{MODEL}.csv\")\n",
    "err_sorted.to_csv(err_csv, index=False)\n",
    "print(\"Saved error CSV ->\", err_csv)\n",
    "\n",
    "# (2) predicted-score distributions \n",
    "def plot_pred_distributions(df, group_col, palette, title_suffix, fname_suffix):\n",
    "    g = sns.FacetGrid(df, hue=group_col, palette=palette, height=5, aspect=1.6)\n",
    "    g.map(sns.histplot, \"y_pred\", kde=True, bins=20, alpha=0.6)\n",
    "    g.add_legend()\n",
    "    g.set_axis_labels(f\"{score} (Predicted)\", \"Number of People\")\n",
    "    plt.title(f\"Distribution of predicted {score} by {title_suffix}\")\n",
    "    out = os.path.join(SAVE_DIR, f\"{TARGET}_pred_distribution_by_{fname_suffix}_{TASK}_{MODEL}.png\")\n",
    "    plt.savefig(out, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(\"Saved plot ->\", out)\n",
    "\n",
    "plot_pred_distributions(sub, \"Gender\",  gender_colors,  \"Gender\",  \"gender\")\n",
    "plot_pred_distributions(sub, \"Country\", country_colors, \"Country\", \"country\")\n",
    "\n",
    "# (3) jointplots (simple, no stats/lines) \n",
    "def common_lims(df, pad=0.25):\n",
    "    lo = np.nanmin([df[\"y_true\"].min(), df[\"y_pred\"].min()]) - pad\n",
    "    hi = np.nanmax([df[\"y_true\"].max(), df[\"y_pred\"].max()]) + pad\n",
    "    return lo, hi\n",
    "\n",
    "lims = common_lims(sub)\n",
    "\n",
    "def joint_with_hue(df, hue, palette, title, outfile):\n",
    "    if df.empty: return\n",
    "    g = sns.jointplot(\n",
    "        data=df, x=\"y_true\", y=\"y_pred\",\n",
    "        hue=hue, kind=\"scatter\",\n",
    "        height=6, space=0.18,              # small gap so marginals don't sit on the frame\n",
    "        palette=palette,\n",
    "        marginal_ticks=True,               # show ticks on marginals\n",
    "        marginal_kws=dict(fill=True, alpha=0.25, common_norm=False)\n",
    "    )\n",
    "\n",
    "    #  main panel: axes visible + identity line + shared limits \n",
    "    g.ax_joint.plot([lims[0], lims[1]], [lims[0], lims[1]], ls=\"--\", lw=1.2, color=\"black\")\n",
    "    g.ax_joint.set_xlim(lims); g.ax_joint.set_ylim(lims)\n",
    "    g.set_axis_labels(f\"{score} (True)\", f\"{score} (Predicted)\")\n",
    "    g.ax_joint.tick_params(axis=\"both\", labelsize=10)\n",
    "    # keep left/bottom spines; hide the extra two so it looks clean\n",
    "    g.ax_joint.spines[\"left\"].set_visible(True)\n",
    "    g.ax_joint.spines[\"bottom\"].set_visible(True)\n",
    "    g.ax_joint.spines[\"top\"].set_visible(False)\n",
    "    g.ax_joint.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    #  marginals: light axes so you can read the scale if needed \n",
    "    for ax in (g.ax_marg_x, g.ax_marg_y):\n",
    "        ax.tick_params(length=3, labelsize=8)  # small ticks/labels\n",
    "        # keep a thin frame\n",
    "        for side in ax.spines:\n",
    "            ax.spines[side].set_linewidth(0.6)\n",
    "\n",
    "    g.fig.suptitle(title, y=1.02)\n",
    "    g.fig.savefig(os.path.join(SAVE_DIR, outfile), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(g.fig)\n",
    "\n",
    "\n",
    "def joint_single(df, title, color, outfile):\n",
    "    if df.empty:\n",
    "        print(f\"[skip] empty subset for {title}\")\n",
    "        return\n",
    "    g = sns.jointplot(\n",
    "        data=df, x=\"y_true\", y=\"y_pred\",\n",
    "        kind=\"scatter\",\n",
    "        height=6, space=0.18,\n",
    "        color=color,\n",
    "        marginal_ticks=True,\n",
    "        marginal_kws=dict(fill=True, alpha=0.25)\n",
    "    )\n",
    "\n",
    "    g.ax_joint.plot([lims[0], lims[1]], [lims[0], lims[1]], ls=\"--\", lw=1.2, color=\"black\")\n",
    "    g.ax_joint.set_xlim(lims); g.ax_joint.set_ylim(lims)\n",
    "    g.set_axis_labels(f\"{score} (True)\", f\"{score} (Predicted)\")\n",
    "    g.ax_joint.tick_params(axis=\"both\", labelsize=10)\n",
    "    g.ax_joint.spines[\"left\"].set_visible(True)\n",
    "    g.ax_joint.spines[\"bottom\"].set_visible(True)\n",
    "    g.ax_joint.spines[\"top\"].set_visible(False)\n",
    "    g.ax_joint.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    for ax in (g.ax_marg_x, g.ax_marg_y):\n",
    "        ax.tick_params(length=3, labelsize=8)\n",
    "        for side in ax.spines:\n",
    "            ax.spines[side].set_linewidth(0.6)\n",
    "\n",
    "    g.fig.suptitle(title, y=1.02)\n",
    "    g.fig.savefig(os.path.join(SAVE_DIR, outfile), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close(g.fig)\n",
    "\n",
    "\n",
    "# by Country (2 colors)\n",
    "joint_with_hue(\n",
    "    sub, \"Country\", country_colors,\n",
    "    f\"{score}: Predicted vs True by Country\",\n",
    "    f\"{TARGET}_joint_by_country_{TASK}_{MODEL}.png\"\n",
    ")\n",
    "\n",
    "# by Gender (2 colors)\n",
    "joint_with_hue(\n",
    "    sub, \"Gender\", gender_colors,\n",
    "    f\"{score}: Predicted vs True by Gender\",\n",
    "    f\"{TARGET}_joint_by_gender_{TASK}_{MODEL}.png\"\n",
    ")\n",
    "\n",
    "# intersections (F-UK, F-USA, M-UK, M-USA)\n",
    "for (g_val, c_val, clr) in [(\"f\",\"uk\",\"tomato\"), (\"f\",\"usa\",\"royalblue\"),\n",
    "                            (\"m\",\"uk\",\"tomato\"), (\"m\",\"usa\",\"royalblue\")]:\n",
    "    ss = sub[(sub[\"Gender\"]==g_val) & (sub[\"Country\"]==c_val)]\n",
    "    if len(ss) < 1:\n",
    "        print(f\"[skip] {g_val.upper()}-{c_val.upper()} empty\"); continue\n",
    "    joint_single(\n",
    "        ss,\n",
    "        f\"{score}: Predicted vs True ({g_val.upper()} / {c_val.upper()})\",\n",
    "        clr,\n",
    "        f\"{TARGET}_joint_{g_val}_{c_val}_{TASK}_{MODEL}.png\"\n",
    "    )\n"
   ],
   "id": "2ef1fd67bfd894cc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved error CSV -> /Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/results/regression/bias/plots/PictureNamingScore_errors_sorted_picnicScene_full.csv\n",
      "Saved plot -> /Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/results/regression/bias/plots/PictureNamingScore_pred_distribution_by_gender_picnicScene_full.png\n",
      "Saved plot -> /Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/results/regression/bias/plots/PictureNamingScore_pred_distribution_by_country_picnicScene_full.png\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-30T18:12:50.667845Z",
     "start_time": "2025-09-30T18:12:49.904029Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# same folder + filename pattern you used before\n",
    "SAVE_DIR = \"/Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/results/regression/bias/plots\"\n",
    "ERR_CSV  = os.path.join(SAVE_DIR, \"PictureNamingScore_errors_sorted_picnicScene_full.csv\")\n",
    "\n",
    "df = pd.read_csv(ERR_CSV)\n",
    "\n",
    "# sanity: keep clean labels\n",
    "df[\"Country\"] = df[\"Country\"].astype(str).str.lower()\n",
    "df[\"Gender\"]  = df[\"Gender\"].astype(str).str.lower()\n",
    "\n",
    "# helper to build one row of summary stats for a given top subset\n",
    "def summarize_top(sub, label):\n",
    "    n = len(sub)\n",
    "    row = {\"bucket\": label, \"n\": n}\n",
    "\n",
    "    # counts\n",
    "    row.update({f\"country_{k}_n\": int(v) for k, v in sub[\"Country\"].value_counts().to_dict().items()})\n",
    "    row.update({f\"gender_{k}_n\":  int(v) for k, v in sub[\"Gender\"].value_counts().to_dict().items()})\n",
    "\n",
    "    # percents within the bucket\n",
    "    for k in [\"uk\",\"usa\"]:\n",
    "        row[f\"country_{k}_pct\"] = (sub[\"Country\"].eq(k).mean() if n > 0 else np.nan)\n",
    "    for k in [\"f\",\"m\"]:\n",
    "        row[f\"gender_{k}_pct\"]  = (sub[\"Gender\"].eq(k).mean()  if n > 0 else np.nan)\n",
    "\n",
    "    return row\n",
    "\n",
    "# overall (baseline) for comparison\n",
    "rows = [summarize_top(df, \"overall\")]\n",
    "\n",
    "# choose some top-k and top-% cutoffs\n",
    "TOP_KS    = [10, 20, 50]\n",
    "TOP_FRACS = [0.10, 0.20]  # 10%, 20%\n",
    "\n",
    "# top-k\n",
    "for k in TOP_KS:\n",
    "    k = min(k, len(df))\n",
    "    rows.append(summarize_top(df.nlargest(k, \"abs_error\"), f\"top_{k}\"))\n",
    "\n",
    "# top-% by absolute error\n",
    "for frac in TOP_FRACS:\n",
    "    k = int(np.ceil(frac * len(df)))\n",
    "    rows.append(summarize_top(df.nlargest(k, \"abs_error\"), f\"top_{int(frac*100)}pct\"))\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "\n",
    "# order columns nicely\n",
    "ordered_cols = (\n",
    "    [\"bucket\",\"n\",\n",
    "     \"country_uk_n\",\"country_usa_n\",\"country_uk_pct\",\"country_usa_pct\",\n",
    "     \"gender_f_n\",\"gender_m_n\",\"gender_f_pct\",\"gender_m_pct\"]\n",
    ")\n",
    "summary = summary.reindex(columns=ordered_cols)\n",
    "\n",
    "# show & save\n",
    "print(summary.to_string(index=False))\n",
    "out_csv = os.path.join(SAVE_DIR, \"highest_error_group_breakdown.csv\")\n",
    "summary.to_csv(out_csv, index=False)\n",
    "print(\"\\nSaved summary ->\", out_csv)\n"
   ],
   "id": "16bc98764c3c980e",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'abs_error'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/nlp_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3805\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3804\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m3805\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_engine\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   3806\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:167\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mindex.pyx:196\u001B[39m, in \u001B[36mpandas._libs.index.IndexEngine.get_loc\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7081\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mpandas/_libs/hashtable_class_helper.pxi:7089\u001B[39m, in \u001B[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[39m\u001B[34m()\u001B[39m\n",
      "\u001B[31mKeyError\u001B[39m: 'abs_error'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[31mKeyError\u001B[39m                                  Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[12]\u001B[39m\u001B[32m, line 42\u001B[39m\n\u001B[32m     40\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m k \u001B[38;5;129;01min\u001B[39;00m TOP_KS:\n\u001B[32m     41\u001B[39m     k = \u001B[38;5;28mmin\u001B[39m(k, \u001B[38;5;28mlen\u001B[39m(df))\n\u001B[32m---> \u001B[39m\u001B[32m42\u001B[39m     rows.append(summarize_top(\u001B[43mdf\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnlargest\u001B[49m\u001B[43m(\u001B[49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mabs_error\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m, \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mtop_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mk\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m\"\u001B[39m))\n\u001B[32m     44\u001B[39m \u001B[38;5;66;03m# top-% by absolute error\u001B[39;00m\n\u001B[32m     45\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m frac \u001B[38;5;129;01min\u001B[39;00m TOP_FRACS:\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/nlp_env/lib/python3.11/site-packages/pandas/core/frame.py:7644\u001B[39m, in \u001B[36mDataFrame.nlargest\u001B[39m\u001B[34m(self, n, columns, keep)\u001B[39m\n\u001B[32m   7525\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mnlargest\u001B[39m(\n\u001B[32m   7526\u001B[39m     \u001B[38;5;28mself\u001B[39m, n: \u001B[38;5;28mint\u001B[39m, columns: IndexLabel, keep: NsmallestNlargestKeep = \u001B[33m\"\u001B[39m\u001B[33mfirst\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   7527\u001B[39m ) -> DataFrame:\n\u001B[32m   7528\u001B[39m \u001B[38;5;250m    \u001B[39m\u001B[33;03m\"\"\"\u001B[39;00m\n\u001B[32m   7529\u001B[39m \u001B[33;03m    Return the first `n` rows ordered by `columns` in descending order.\u001B[39;00m\n\u001B[32m   7530\u001B[39m \n\u001B[32m   (...)\u001B[39m\u001B[32m   7642\u001B[39m \u001B[33;03m    Brunei      434000    12128      BN\u001B[39;00m\n\u001B[32m   7643\u001B[39m \u001B[33;03m    \"\"\"\u001B[39;00m\n\u001B[32m-> \u001B[39m\u001B[32m7644\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mselectn\u001B[49m\u001B[43m.\u001B[49m\u001B[43mSelectNFrame\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn\u001B[49m\u001B[43m=\u001B[49m\u001B[43mn\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkeep\u001B[49m\u001B[43m=\u001B[49m\u001B[43mkeep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m=\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mnlargest\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/nlp_env/lib/python3.11/site-packages/pandas/core/methods/selectn.py:57\u001B[39m, in \u001B[36mSelectN.nlargest\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m     55\u001B[39m \u001B[38;5;129m@final\u001B[39m\n\u001B[32m     56\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mnlargest\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m---> \u001B[39m\u001B[32m57\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m\"\u001B[39;49m\u001B[33;43mnlargest\u001B[39;49m\u001B[33;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/nlp_env/lib/python3.11/site-packages/pandas/core/methods/selectn.py:199\u001B[39m, in \u001B[36mSelectNFrame.compute\u001B[39m\u001B[34m(self, method)\u001B[39m\n\u001B[32m    196\u001B[39m columns = \u001B[38;5;28mself\u001B[39m.columns\n\u001B[32m    198\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m column \u001B[38;5;129;01min\u001B[39;00m columns:\n\u001B[32m--> \u001B[39m\u001B[32m199\u001B[39m     dtype = \u001B[43mframe\u001B[49m\u001B[43m[\u001B[49m\u001B[43mcolumn\u001B[49m\u001B[43m]\u001B[49m.dtype\n\u001B[32m    200\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m.is_valid_dtype_n_method(dtype):\n\u001B[32m    201\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[32m    202\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mColumn \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mrepr\u001B[39m(column)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m has dtype \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdtype\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m, \u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    203\u001B[39m             \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33mcannot use method \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mrepr\u001B[39m(method)\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m with this dtype\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    204\u001B[39m         )\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/nlp_env/lib/python3.11/site-packages/pandas/core/frame.py:4102\u001B[39m, in \u001B[36mDataFrame.__getitem__\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   4100\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.columns.nlevels > \u001B[32m1\u001B[39m:\n\u001B[32m   4101\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._getitem_multilevel(key)\n\u001B[32m-> \u001B[39m\u001B[32m4102\u001B[39m indexer = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mcolumns\u001B[49m\u001B[43m.\u001B[49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   4103\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[32m   4104\u001B[39m     indexer = [indexer]\n",
      "\u001B[36mFile \u001B[39m\u001B[32m/opt/anaconda3/envs/nlp_env/lib/python3.11/site-packages/pandas/core/indexes/base.py:3812\u001B[39m, in \u001B[36mIndex.get_loc\u001B[39m\u001B[34m(self, key)\u001B[39m\n\u001B[32m   3807\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(casted_key, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;129;01mor\u001B[39;00m (\n\u001B[32m   3808\u001B[39m         \u001B[38;5;28misinstance\u001B[39m(casted_key, abc.Iterable)\n\u001B[32m   3809\u001B[39m         \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28many\u001B[39m(\u001B[38;5;28misinstance\u001B[39m(x, \u001B[38;5;28mslice\u001B[39m) \u001B[38;5;28;01mfor\u001B[39;00m x \u001B[38;5;129;01min\u001B[39;00m casted_key)\n\u001B[32m   3810\u001B[39m     ):\n\u001B[32m   3811\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m InvalidIndexError(key)\n\u001B[32m-> \u001B[39m\u001B[32m3812\u001B[39m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34;01merr\u001B[39;00m\n\u001B[32m   3813\u001B[39m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[32m   3814\u001B[39m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[32m   3815\u001B[39m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[32m   3816\u001B[39m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[32m   3817\u001B[39m     \u001B[38;5;28mself\u001B[39m._check_indexing_error(key)\n",
      "\u001B[31mKeyError\u001B[39m: 'abs_error'"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-01T06:44:35.675882Z",
     "start_time": "2025-10-01T06:44:35.660683Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = \"/Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/results/regression/bias/plots/PictureNamingScore_errors_sorted_picnicScene_full.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# ensure 'error' exists; if not, build it from y_true - y_pred\n",
    "if \"error\" not in df.columns and {\"y_true\",\"y_pred\"}.issubset(df.columns):\n",
    "    df[\"error\"] = df[\"y_true\"] - df[\"y_pred\"]\n",
    "\n",
    "# drop rows with missing essentials to match behavior consistently\n",
    "sub = df.dropna(subset=[\"y_true\", \"error\", \"Country\"]).copy()\n",
    "\n",
    "res = (\n",
    "    sub.groupby(\"Country\", dropna=False)\n",
    "       .apply(lambda x: pd.Series({\n",
    "           \"n\": len(x),\n",
    "           \"mse\": np.mean(np.square(x[\"error\"])),            # 1/n * Σ err^2\n",
    "           \"var\": x[\"y_true\"].var(ddof=1),                   # sample variance (matches .var())\n",
    "           \"r^2\": 1 - np.mean(np.square(x[\"error\"])) / x[\"y_true\"].var(ddof=1),\n",
    "           # \"r^2_sk\": metrics.r2_score(x[\"y_true\"], x[\"y_pred\"]) if {\"y_true\",\"y_pred\"}.issubset(x.columns) else np.nan,\n",
    "           \"rmse\": np.sqrt(np.mean(np.square(x[\"error\"]))),\n",
    "           \"mae\": np.mean(np.abs(x[\"error\"])),\n",
    "       }))\n",
    "       .reset_index()\n",
    "       .sort_values(\"Country\")  # or .sort_values(\"r^2\", ascending=False)\n",
    ")\n",
    "\n",
    "print(res.to_string(index=False))\n"
   ],
   "id": "9271f8fa955a52bb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Country     n     mse      var      r^2     rmse      mae\n",
      "     uk 482.0 4.65052 5.024064 0.074351 2.156506 1.551631\n",
      "    usa 477.0 6.40433 9.797403 0.346324 2.530678 1.824596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gp/zgb_1js56gq706y7rfrpmmvh0000gn/T/ipykernel_20551/3288649543.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-02T14:54:13.003864Z",
     "start_time": "2025-11-02T14:54:12.972569Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "path = \"/Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/results/regression/bias/predicted_vs_actual_scores/PictureNamingScore_errors_sorted_picnicScene_full.csv\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# ensure 'error' exists; if not, build it from y_true - y_pred\n",
    "if \"error\" not in df.columns and {\"y_true\",\"y_pred\"}.issubset(df.columns):\n",
    "    df[\"error\"] = df[\"y_true\"] - df[\"y_pred\"]\n",
    "\n",
    "# drop rows with missing essentials to match behavior consistently\n",
    "sub = df.dropna(subset=[\"y_true\", \"error\", \"Gender\"]).copy()\n",
    "\n",
    "res = (\n",
    "    sub.groupby(\"Gender\", dropna=False)\n",
    "       .apply(lambda x: pd.Series({\n",
    "           \"n\": len(x),\n",
    "           \"mse\": np.mean(np.square(x[\"error\"])),            # 1/n * Σ err^2\n",
    "           \"var\": x[\"y_true\"].var(ddof=1),                   # sample variance (matches .var())\n",
    "           \"r^2\": 1 - np.mean(np.square(x[\"error\"])) / x[\"y_true\"].var(ddof=1),\n",
    "           # \"r^2_sk\": metrics.r2_score(x[\"y_true\"], x[\"y_pred\"]) if {\"y_true\",\"y_pred\"}.issubset(x.columns) else np.nan,\n",
    "           \"rmse\": np.sqrt(np.mean(np.square(x[\"error\"]))),\n",
    "           \"mae\": np.mean(np.abs(x[\"error\"])),\n",
    "       }))\n",
    "       .reset_index()\n",
    "       .sort_values(\"Gender\")  # or .sort_values(\"r^2\", ascending=False)\n",
    ")\n",
    "\n",
    "print(res.to_string(index=False))\n"
   ],
   "id": "50e79867982c624f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gender     n      mse       var      r^2     rmse      mae\n",
      "     f 588.0 5.043957  5.828191 0.134559 2.245875 1.618516\n",
      "     m 371.0 6.281859 10.120420 0.379289 2.506364 1.796581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/py/1h2n_yxd7l9dts6tjm4v1tpr0000gn/T/ipykernel_34159/4094145968.py:16: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  .apply(lambda x: pd.Series({\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
