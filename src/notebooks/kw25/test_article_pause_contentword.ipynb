{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "test feature: number of pauses that follow an article and precede content words (Vincze et al., 2022) to feature set\n",
   "id": "543170a1d4be1974"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# test function for one participant\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def debug_article_pause_contentword(word_timestamp_file, pause=0.15):\n",
    "    print(f\"\\nloading file: {word_timestamp_file}\")\n",
    "    df = pd.read_csv(word_timestamp_file)\n",
    "\n",
    "    def get_tag(word):\n",
    "        if isinstance(word, str) and word.strip():\n",
    "            return nlp(word)[0].tag_\n",
    "        return None\n",
    "\n",
    "    df[\"tag\"] = df[\"word\"].apply(get_tag)\n",
    "\n",
    "    print(\"\\nfirst few rows with tags:\")\n",
    "    print(df[[\"word\", \"start\", \"end\", \"tag\"]].head(10))\n",
    "\n",
    "    article_tags = {\"DT\"}\n",
    "    content_tags = {\"NN\", \"NNS\", \"NNP\", \"NNPS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"JJ\", \"JJR\", \"JJS\"}\n",
    "    filled_pauses = {\"UH\"}\n",
    "\n",
    "    pause_count = 0\n",
    "    total_DT_content_links = 0  \n",
    "    i = 0\n",
    "\n",
    "    print(\"\\nchecking for DT ➝ pause ➝ content OR DT ➝ UH ➝ pause ➝ content\")\n",
    "\n",
    "    while i < len(df) - 1:\n",
    "        current_tag = df.loc[i, \"tag\"]\n",
    "        current_word = df.loc[i, \"word\"]\n",
    "\n",
    "        if current_tag in article_tags:\n",
    "            j = i + 1\n",
    "\n",
    "            # case: article -> filled pause -> content-word\n",
    "            if df.loc[j, \"tag\"] in filled_pauses:\n",
    "                j += 1\n",
    "                if j >= len(df):\n",
    "                    break\n",
    "\n",
    "                next_tag = df.loc[j, \"tag\"]\n",
    "                if next_tag in content_tags:\n",
    "                    pause_duration = df.loc[j, \"start\"] - df.loc[i, \"end\"]\n",
    "                    print(f\"→ '{current_word}' (DT) ➝ '{df.loc[i+1, 'word']}' (UH) ➝ '{df.loc[j, 'word']}' ({next_tag}) | Pause: {pause_duration:.3f}s\")\n",
    "                    total_DT_content_links += 1\n",
    "                    if pause_duration > pause:\n",
    "                        print(f\"matched DT ➝ UH ➝ pause ➝ content: '{current_word}' ➝ '{df.loc[i+1, 'word']}' ➝ '{df.loc[j, 'word']}'\")\n",
    "                        pause_count += 1\n",
    "                i = j\n",
    "                continue\n",
    "\n",
    "            # case: article -> silent pause -> content-word\n",
    "            next_tag = df.loc[j, \"tag\"]\n",
    "            if next_tag in content_tags:\n",
    "                pause_duration = df.loc[j, \"start\"] - df.loc[i, \"end\"]\n",
    "                print(f\"→ '{current_word}' (DT) ➝ '{df.loc[j, 'word']}' ({next_tag}) | Pause: {pause_duration:.3f}s\")\n",
    "                total_DT_content_links += 1\n",
    "                if pause_duration > pause:\n",
    "                    print(f\"matched DT ➝ pause ➝ content: '{current_word}' ➝ '{df.loc[j, 'word']}'\")\n",
    "                    pause_count += 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    print(f\"\\ntotal matches: {pause_count}\")\n",
    "    print(f\"total DT ➝ content links: {total_DT_content_links}\")\n",
    "\n",
    "    if total_DT_content_links > 0:\n",
    "        ratio = pause_count / total_DT_content_links\n",
    "        print(f\"ratio: {ratio:.2f}\")\n",
    "    else:\n",
    "        print(\"ratio: N/A (no DT ➝ content links found)\")\n",
    "\n",
    "    return pause_count, total_DT_content_links, ratio if total_DT_content_links > 0 else None\n"
   ],
   "id": "887d5b6809345bfb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "subject_id = \"41\"\n",
    "timestamp_file = f\"/Volumes/methlab/Students/Gila/word_timestamps/cookieTheft/google/timestamps/{subject_id}.csv\"\n",
    "debug_article_pause_contentword(timestamp_file)"
   ],
   "id": "6302323c524c460a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def debug_article_pause_patterns(word_timestamp_file, pause_threshold=0.15):\n",
    "    print(f\"\\nloading file: {word_timestamp_file}\")\n",
    "    df = pd.read_csv(word_timestamp_file)\n",
    "\n",
    "    # POS-tag row by row\n",
    "    def get_pos(word):\n",
    "        if word == \"[pause]\":\n",
    "            return \"PAUSE\"\n",
    "        try:\n",
    "            doc = nlp(word)\n",
    "            return doc[0].tag_ if doc else \"X\"\n",
    "        except:\n",
    "            return \"X\"\n",
    "\n",
    "    df[\"pos\"] = df[\"word\"].apply(get_pos)\n",
    "\n",
    "    # Insert [pause] rows\n",
    "    pause_rows = []\n",
    "    for i in range(1, len(df)):\n",
    "        pause = df.loc[i, \"start\"] - df.loc[i - 1, \"end\"]\n",
    "        if pause > pause_threshold:\n",
    "            pause_row = {\n",
    "                \"word\": \"[pause]\",\n",
    "                \"start\": df.loc[i - 1, \"end\"],\n",
    "                \"end\": df.loc[i, \"start\"],\n",
    "                \"pos\": \"PAUSE\"\n",
    "            }\n",
    "            pause_rows.append((i, pause_row))\n",
    "\n",
    "    for idx, row in reversed(pause_rows):\n",
    "        df = pd.concat([df.iloc[:idx], pd.DataFrame([row]), df.iloc[idx:]], ignore_index=True)\n",
    "\n",
    "    # Categorize POS\n",
    "    def categorize(tag):\n",
    "        if tag in {\"UH\", \"PAUSE\"}:\n",
    "            return \"PAUSE\"\n",
    "        elif tag == \"DT\":\n",
    "            return \"ARTICLE\"\n",
    "        elif tag in {\n",
    "            \"NN\", \"NNS\", \"NNP\", \"NNPS\",\n",
    "            \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\",\n",
    "            \"JJ\", \"JJR\", \"JJS\"\n",
    "        }:\n",
    "            return \"CONTENT\"\n",
    "        else:\n",
    "            return \"OTHER\"\n",
    "\n",
    "    df[\"pos_category\"] = df[\"pos\"].apply(categorize)\n",
    "\n",
    "    # Show output\n",
    "    pd.set_option('display.max_rows', None)\n",
    "    print(\"\\nfirst few rows (with POS tags and categories):\")\n",
    "    print(df[[\"word\", \"start\", \"end\", \"pos\", \"pos_category\"]].head(130))\n",
    "\n",
    "    print(\"\\nPOS category sequence:\")\n",
    "    print(df[\"pos_category\"].tolist())\n",
    "\n",
    "    # Match patterns\n",
    "    patterns = [\n",
    "        [\"ARTICLE\", \"PAUSE\", \"CONTENT\"],\n",
    "        [\"ARTICLE\", \"PAUSE\", \"ARTICLE\", \"CONTENT\"],\n",
    "        [\"ARTICLE\", \"PAUSE\", \"ARTICLE\", \"PAUSE\", \"CONTENT\"]\n",
    "    ]\n",
    "    sequence = df[\"pos_category\"].tolist()\n",
    "\n",
    "    total_article_content = sum(\n",
    "        1 for i in range(len(sequence) - 1)\n",
    "        if sequence[i] == \"ARTICLE\" and sequence[i + 1] == \"CONTENT\"\n",
    "    )\n",
    "\n",
    "    match_count = 0\n",
    "    print(\"\\nChecking for pattern matches...\")\n",
    "    for i in range(len(sequence)):\n",
    "        for pattern in patterns:\n",
    "            if sequence[i:i + len(pattern)] == pattern:\n",
    "                words_matched = df[\"word\"].iloc[i:i + len(pattern)].tolist()\n",
    "                print(f\"Matched pattern {pattern}: {words_matched}\")\n",
    "                match_count += 1\n",
    "                break\n",
    "\n",
    "    print(f\"\\nTotal pattern matches: {match_count}\")\n",
    "    print(f\"Total ARTICLE ➝ CONTENT transitions: {total_article_content}\")\n",
    "    ratio = match_count / total_article_content if total_article_content > 0 else None\n",
    "    print(f\"Ratio: {ratio:.2f}\" if ratio is not None else \"Ratio: N/A\")\n",
    "\n",
    "    return match_count, total_article_content, ratio\n",
    "\n",
    "# use for example-subject\n",
    "subject_id = \"41\"\n",
    "task = \"cookieTheft\"\n",
    "timestamp_file = f\"/Volumes/methlab/Students/Gila/word_timestamps/{task}/google/timestamps/{subject_id}.csv\"\n",
    "debug_article_pause_patterns(timestamp_file)\n"
   ],
   "id": "b8bcc3946592a02d",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
