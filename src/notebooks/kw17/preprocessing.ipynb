{
 "cells": [
  {
   "cell_type": "code",
   "id": "82e5bd3a25e169d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T16:48:00.796403Z",
     "start_time": "2025-04-30T16:48:00.755181Z"
    }
   },
   "source": [
    "# based on IQR, but read more about that and do something else\n",
    "\n",
    "# setup\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# add project root to sys.path\n",
    "sys.path.append(\"/Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/src\")\n",
    "\n",
    "from config.constants import GIT_DIRECTORY\n",
    "\n",
    "# task and target\n",
    "task_name = \"cookieTheft\"\n",
    "target = \"PhonemicFluencyScore\"\n",
    "\n",
    "# paths\n",
    "features_path = os.path.join(GIT_DIRECTORY, f\"results/features/{task_name}.csv\")\n",
    "scores_path = os.path.join(GIT_DIRECTORY, \"resources/language_scores_all_subjects.csv\")\n",
    "\n",
    "# load data\n",
    "features = pd.read_csv(features_path)\n",
    "scores = pd.read_csv(scores_path)\n",
    "\n",
    "# merge and drop missing\n",
    "df = pd.merge(features, scores[[\"Subject_ID\", target]], on=\"Subject_ID\").dropna()\n",
    "print(f\"Original merged size: {len(df)}\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original merged size: 957\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T16:48:03.338817Z",
     "start_time": "2025-04-30T16:48:03.334071Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# function to remove outliers based on IQR (and return removed subject IDs)\n",
    "\n",
    "def remove_iqr_outliers(df, column, subject_id=\"Subject_ID\", verbose=True):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    filtered = df[(df[column] >= lower) & (df[column] <= upper)]\n",
    "    removed_df = df[(df[column] < lower) | (df[column] > upper)]\n",
    "    percent = 100 * len(removed_df) / len(df)\n",
    "    if verbose:\n",
    "        print(f\"{column}: Removed {len(removed_df)} rows ({percent:.2f}%) | Range kept: {lower:.2f} to {upper:.2f}\")\n",
    "    return filtered, removed_df[[subject_id, column]]\n"
   ],
   "id": "6e44edb13e386146",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T16:49:04.161102Z",
     "start_time": "2025-04-30T16:49:03.607025Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# clean all three scores and collect removed subject IDs\n",
    "targets = [\"PhonemicFluencyScore\", \"SemanticFluencyScore\", \"PictureNamingScore\"]\n",
    "removed_ids_all = []\n",
    "\n",
    "# plot original distributions\n",
    "for score in targets:\n",
    "    plot_score_distribution(scores, score, \"Before Cleaning\", f\"{score}_before_cleaning\")\n",
    "\n",
    "# remove outliers\n",
    "for score in targets:\n",
    "    _, removed = remove_iqr_outliers(scores, score)\n",
    "    removed_ids_all.append(removed[\"Subject_ID\"])"
   ],
   "id": "cb1d57cc69b1781c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PhonemicFluencyScore: Removed 7 rows (0.70%) | Range kept: 3.00 to 27.00\n",
      "SemanticFluencyScore: Removed 9 rows (0.90%) | Range kept: 5.00 to 37.00\n",
      "PictureNamingScore: Removed 80 rows (7.98%) | Range kept: 14.00 to 22.00\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T16:49:07.138825Z",
     "start_time": "2025-04-30T16:49:06.588522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# combine all removed subject IDs\n",
    "all_removed_ids = pd.concat(removed_ids_all).drop_duplicates()\n",
    "print(f\"Total unique subjects removed: {len(all_removed_ids)}\")\n",
    "\n",
    "# filter scores â†’ keep only non-outlier subjects\n",
    "scores_cleaned = scores[~scores[\"Subject_ID\"].isin(all_removed_ids)]\n",
    "\n",
    "# plot cleaned distributions\n",
    "for score in targets:\n",
    "    plot_score_distribution(scores_cleaned, score, \"After Cleaning\", f\"{score}_after_cleaning\")"
   ],
   "id": "d99d7af7db9c9fd8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique subjects removed: 94\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T16:49:09.463703Z",
     "start_time": "2025-04-30T16:49:09.454271Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save final cleaned scores\n",
    "combined_path = os.path.join(GIT_DIRECTORY, \"resources/combined_language_scores_cleaned.csv\")\n",
    "scores_cleaned.to_csv(combined_path, index=False)\n",
    "print(f\"Cleaned combined scores saved to:\\n{combined_path}\")\n",
    "\n",
    "# save outlier Subject_IDs\n",
    "outlier_log_path = os.path.join(GIT_DIRECTORY, \"results/preprocessing/removed_subject_ids_combined.csv\")\n",
    "all_removed_ids.to_frame(name=\"Subject_ID\").to_csv(outlier_log_path, index=False)\n",
    "print(f\"Removed subject IDs saved to:\\n{outlier_log_path}\")"
   ],
   "id": "b290758e1adbf268",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned combined scores saved to:\n",
      "/Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/resources/combined_language_scores_cleaned.csv\n",
      "Removed subject IDs saved to:\n",
      "/Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/results/preprocessing/removed_subject_ids_combined.csv\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-30T16:49:12.856542Z",
     "start_time": "2025-04-30T16:49:11.702041Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# new score distribution plots\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "\n",
    "def plot_score_distribution(data, column, title_suffix, filename_suffix):\n",
    "    score_counts = data[column].value_counts().sort_index()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(score_counts.index, score_counts.values, color=\"slateblue\", edgecolor=\"black\", width=1.0)\n",
    "    plt.xlabel(\"Score\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.ylabel(\"Number of People\", fontsize=14, fontweight=\"bold\")\n",
    "    plt.title(f\"{column} Score Distribution ({title_suffix})\", fontsize=16, fontweight=\"bold\")\n",
    "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "\n",
    "    # save to plots folder\n",
    "    filename_suffix = title_suffix.lower().replace(\" \", \"_\")\n",
    "    filename = f\"{column}_{filename_suffix}.png\"\n",
    "    output_plot_path = os.path.join(GIT_DIRECTORY, \"results/plots\", filename)\n",
    "    os.makedirs(os.path.dirname(output_plot_path), exist_ok=True)\n",
    "    plt.savefig(output_plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# plot for each score (before + after)\n",
    "for score in targets:\n",
    "    plot_score_distribution(scores, score, \"Before Cleaning\", \"before_cleaning\")\n",
    "    plot_score_distribution(scores_cleaned, score, \"After Cleaning\", \"after_cleaning\")\n",
    "\n"
   ],
   "id": "3ce670bb8cfc46bb",
   "outputs": [],
   "execution_count": 12
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
