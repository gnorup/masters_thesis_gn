{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "remove outliers: cut audio files that have a duration longer than five minutes to five minutes.",
   "id": "9e7cfa0c2821fff2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:32:25.217998Z",
     "start_time": "2025-06-15T14:32:20.902548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setup\n",
    "\n",
    "import sys\n",
    "\n",
    "# add the root of the project to the path\n",
    "sys.path.append(\"/Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/src\")\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "\n",
    "from feature_extraction.features import (\n",
    "    n_words, clean_text, tokenize, pos_ratios_spacy, filler_word_ratio,\n",
    "    ttr, mattr, avg_word_length,\n",
    "    light_verb_ratio, empty_word_ratio, nid_ratio, adjacent_repetitions,\n",
    "    brunets_index, honores_statistic, guirauds_statistic\n",
    ")\n",
    "\n",
    "from feature_extraction.features.psycholinguistic_features import (\n",
    "    compute_avg_by_pos, load_aoa_lexicon, load_imageability_norms,\n",
    "    load_familiarity_norms, load_frequency_norms, load_concreteness_lexicon\n",
    ")\n",
    "from feature_extraction.features.fluency_features import filled_pause_ratio, calculate_fluency_features\n",
    "\n",
    "from feature_extraction.audio import (\n",
    "    count_phonemes, extract_acoustic_features,\n",
    "    extract_egemaps, VoiceActivityDetector\n",
    ")\n",
    "\n",
    "from config.constants import DATA_DIRECTORY\n",
    "from config.constants import GIT_DIRECTORY\n"
   ],
   "id": "5ce64bbc07611952",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to /Users/gilanorup/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:32:46.469546Z",
     "start_time": "2025-06-15T14:32:25.228718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# trim audio\n",
    "\n",
    "def trim_audio(input_path, output_path, duration_sec=300):\n",
    "    audio = AudioSegment.from_wav(input_path)\n",
    "    trimmed = audio[:duration_sec * 1000] # bc pydub uses ms\n",
    "    trimmed.export(output_path, format=\"wav\")\n",
    "\n",
    "original_audio_path = os.path.join(DATA_DIRECTORY, \"1370\", \"cookieTheft.wav\")\n",
    "trimmed_audio_path = os.path.join(GIT_DIRECTORY, \"data\", \"1370_cookieTheft_trimmed.wav\")\n",
    "\n",
    "trim_audio(original_audio_path, trimmed_audio_path)"
   ],
   "id": "b17896e25a0312cc",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:32:46.520629Z",
     "start_time": "2025-06-15T14:32:46.510760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# calculate duration of trimmed audio file (to make sure + for feature-calculation later)\n",
    "\n",
    "trimmed_audio = AudioSegment.from_wav(trimmed_audio_path)\n",
    "total_duration = len(trimmed_audio) / 1000  # -> seconds\n"
   ],
   "id": "a830501ff4abbd58",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:32:46.531109Z",
     "start_time": "2025-06-15T14:32:46.525625Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# compute features for subjects for only five minutes of the audio-file\n",
    "\n",
    "def calculate_features_exception(text, audio_path, total_duration, Subject_ID = 1370):\n",
    "\n",
    "    concreteness_lexicon = load_concreteness_lexicon()\n",
    "    aoa_lexicon = load_aoa_lexicon()\n",
    "    frequency_lexicon = load_frequency_norms()\n",
    "    familiarity_lexicon = load_familiarity_norms()\n",
    "    imageability_lexicon = load_imageability_norms()\n",
    "\n",
    "    features = {}\n",
    "\n",
    "    # linguistic features\n",
    "    features[\"n_words\"] = n_words(text)\n",
    "    features[\"ttr\"] = ttr(text)\n",
    "    features.update(mattr(text, window_sizes=[10, 20, 30, 40, 50]))\n",
    "    features[\"filler_word_ratio\"] = filler_word_ratio(text)\n",
    "    features[\"average_word_length\"] = avg_word_length(text)\n",
    "    features[\"brunets_index\"] = brunets_index(text)\n",
    "    features[\"honores_statistic\"] = honores_statistic(text)\n",
    "    features[\"guirauds_statistic\"] = guirauds_statistic(text)\n",
    "    features[\"light_verb_ratio\"] = light_verb_ratio(text)\n",
    "    features[\"empty_word_ratio\"] = empty_word_ratio(text)\n",
    "    features[\"nid_ratio\"] = nid_ratio(text)\n",
    "    features[\"adjacent_repetitions\"] = adjacent_repetitions(text)\n",
    "    features[\"aoa_content\"] = compute_avg_by_pos(text, aoa_lexicon, [\"NOUN\", \"VERB\", \"ADJ\"])\n",
    "    features[\"aoa_nouns\"] = compute_avg_by_pos(text, aoa_lexicon, [\"NOUN\"])\n",
    "    features[\"aoa_verbs\"] = compute_avg_by_pos(text, aoa_lexicon, [\"VERB\"])\n",
    "    features[\"fam_content\"] = compute_avg_by_pos(text, familiarity_lexicon, [\"NOUN\", \"VERB\", \"ADJ\"])\n",
    "    features[\"fam_nouns\"] = compute_avg_by_pos(text, familiarity_lexicon, [\"NOUN\"])\n",
    "    features[\"fam_verbs\"] = compute_avg_by_pos(text, familiarity_lexicon, [\"VERB\"])\n",
    "    features[\"img_content\"] = compute_avg_by_pos(text, imageability_lexicon, [\"NOUN\", \"VERB\", \"ADJ\"])\n",
    "    features[\"img_nouns\"] = compute_avg_by_pos(text, imageability_lexicon, [\"NOUN\"])\n",
    "    features[\"img_verbs\"] = compute_avg_by_pos(text, imageability_lexicon, [\"VERB\"])\n",
    "    features[\"freq_content\"] = compute_avg_by_pos(text, frequency_lexicon, [\"NOUN\", \"VERB\", \"ADJ\"])\n",
    "    features[\"freq_nouns\"] = compute_avg_by_pos(text, frequency_lexicon, [\"NOUN\"])\n",
    "    features[\"freq_verbs\"] = compute_avg_by_pos(text, frequency_lexicon, [\"VERB\"])\n",
    "    features[\"concr_content\"] = compute_avg_by_pos(text, concreteness_lexicon, [\"NOUN\", \"VERB\", \"ADJ\"])\n",
    "    features[\"concr_nouns\"] = compute_avg_by_pos(text, concreteness_lexicon, [\"NOUN\"])\n",
    "    features[\"concr_verbs\"] = compute_avg_by_pos(text, concreteness_lexicon, [\"VERB\"])\n",
    "    features.update(pos_ratios_spacy(text))\n",
    "    features.update(calculate_fluency_features(text))\n",
    "\n",
    "    # acoustic features\n",
    "    acoustic = extract_acoustic_features(audio_path, text, total_duration)\n",
    "    egemaps = extract_egemaps(audio_path)\n",
    "    features.update(acoustic)\n",
    "    features.update(egemaps)\n",
    "\n",
    "    return pd.DataFrame([{**{\"Subject_ID\": Subject_ID}, **features}])"
   ],
   "id": "ecdfdeddcfadd1df",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:33:01.393291Z",
     "start_time": "2025-06-15T14:32:46.539935Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# calculate for Subject 1370\n",
    "shortened_transcription = \"\"\"i see a kitchen scene based on the style of hair of the woman doing the dishes, i would say it's from the 50s, uh, got a young boy standing on top of a stool that is tipping, reaching for a cookie jar, having what might be chocolate chip or raisin.\n",
    " oatmeal cookies based on the spots on the cookies and the cookie jar has the lid off and is on the top shelf of the upper kitchen cabinet, i see a little girl, i would presume to be his sister, standing next to the stool, reaching up, waiting for a cookie, the boy has one already in his left hand while he's reaching for another in his right hand with his right hand,\n",
    " \"the girl has her right hand over her mouth and is smiling, the girl is wearing a dress with a short skirt and her shoes are, they look like mary jane's, the stool is a three-legged stool by the way, the boy is wearing, his shoes are...\"\n",
    " yeah, well they it looks like he's just wearing socks, possibly because the toe and the heel are marked and the part covering the ankle is somewhat sagging. he's also wearing a collared shirt and short sleeve and the girls dresses short sleeve as well. the boys wearing collar shirt, short sleeve.\n",
    " with short pants that come down to mid thigh, the coup from which he is extracting cookies, has a hinge on the left side, it's one of three cupboards hanging on the wall which is directly opposite the view of the...\n",
    " three hanging on the wall with two below, the doors are simple rectangles with a bar handle protruding slightly, having two posts holding it out from the door to allow for gripping, the boy has one leg straight,\n",
    " on the centered more or less on the top of the stool, his right leg, his left leg is bent at the knee and standing with in place with the arch of the foot over the upper edge of the stool as it's tilting, the stool looks tilted enough to where he the boy is probably in the process.\n",
    " of falling, the mother has gin length hair, curled under at the bottom, curled under, curled under at the bottom, she's wearing a round neck, sleeveless dress with knee length, it's knee length, and a an apron,\n",
    " of the type just tied around her waist and going nearly as going down nearly as long as her dress, she has on uh some type of simple closed toe shoe with a low heel, oh just to go back to the girl's shoes, um, she's also wearing socks and the shoes she's wearing are closed toe.\n",
    " with a strap over the top of the arch and no visible heels, back to the woman, she's standing primarily with her weight on her right leg, which is pointed to the right, she's facing, or rather she is standing next to,\n",
    " the\"\"\"\n",
    "audio_path = trimmed_audio_path\n",
    "\n",
    "df_cut = calculate_features_exception(shortened_transcription, audio_path, total_duration=total_duration)\n",
    "print(df_cut)"
   ],
   "id": "512142b1b8f7ab8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Subject_ID  n_words       ttr  mattr_10  mattr_20  mattr_30  mattr_40  \\\n",
      "0        1370      498  0.407631  0.912679  0.841336  0.788628  0.752124   \n",
      "\n",
      "   mattr_50  filler_word_ratio  average_word_length  ...  \\\n",
      "0  0.719866           0.014056             4.048193  ...   \n",
      "\n",
      "   eGeMAPS_slopeUV0-500_sma3nz_amean  eGeMAPS_slopeUV500-1500_sma3nz_amean  \\\n",
      "0                           0.026431                             -0.006015   \n",
      "\n",
      "   eGeMAPS_spectralFluxUV_sma3nz_amean  eGeMAPS_loudnessPeaksPerSec  \\\n",
      "0                             0.094161                     1.650055   \n",
      "\n",
      "   eGeMAPS_VoicedSegmentsPerSec  eGeMAPS_MeanVoicedSegmentLengthSec  \\\n",
      "0                       1.72707                            0.294208   \n",
      "\n",
      "   eGeMAPS_StddevVoicedSegmentLengthSec  eGeMAPS_MeanUnvoicedSegmentLength  \\\n",
      "0                              0.304693                           0.296849   \n",
      "\n",
      "   eGeMAPS_StddevUnvoicedSegmentLength  eGeMAPS_equivalentSoundLevel_dBp  \n",
      "0                             0.506396                        -25.582672  \n",
      "\n",
      "[1 rows x 157 columns]\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-15T14:33:01.555862Z",
     "start_time": "2025-06-15T14:33:01.397776Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# update in cookieTheft features .csv\n",
    "df = pd.read_csv(os.path.join(GIT_DIRECTORY, \"results\", \"features\", \"cookieTheft.csv\"))\n",
    "df = df[df[\"Subject_ID\"] != 1370]\n",
    "df = pd.concat([df, df_cut], ignore_index=True).sort_values(\"Subject_ID\")\n",
    "df.to_csv(os.path.join(GIT_DIRECTORY, \"results\", \"features\", \"cookieTheft.csv\"), index=False)"
   ],
   "id": "992b5b03fb5e3f9",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
