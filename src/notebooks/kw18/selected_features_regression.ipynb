{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T17:51:13.611993Z",
     "start_time": "2025-05-01T17:51:13.555192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# setup\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# project path setup\n",
    "sys.path.append(\"/Users/gilanorup/Desktop/Studium/MSc/MA/code/masters_thesis_gn/src\")\n",
    "\n",
    "from config.constants import GIT_DIRECTORY\n",
    "from regression.train_regression_models import train_and_evaluate_regression_model\n",
    "from feature_selection.feature_selection_functions import load_filtered_features\n",
    "\n",
    "\n",
    "task_name = \"cookieTheft\"\n",
    "target = \"PhonemicFluencyScore\"\n",
    "\n",
    "selected_columns = [\n",
    "    \"n_words\",\n",
    "    \"ttr\",\n",
    "    \"mattr\",\n",
    "    \"filler_word_ratio\",\n",
    "    \"concreteness_score\",\n",
    "    \"aoa_average\",\n",
    "    \"average_word_length\",\n",
    "    \"brunets_index\",\n",
    "    \"honores_statistic\",\n",
    "    \"guirauds_statistic\",\n",
    "    \"ADJ\",\n",
    "    \"ADP\",\n",
    "    \"ADV\",\n",
    "    \"AUX\",\n",
    "    \"CCONJ\",\n",
    "    \"DET\",\n",
    "    \"INTJ\",\n",
    "    \"NOUN\",\n",
    "    \"NUM\",\n",
    "    \"PART\",\n",
    "    \"PRON\",\n",
    "    \"SCONJ\",\n",
    "    \"VERB\",\n",
    "    \"NOUN/VERB\",\n",
    "    \"PRON/NOUN\",\n",
    "    \"DET/NOUN\",\n",
    "    \"AUX/VERB\",\n",
    "    \"OPEN/CLOSED\",\n",
    "    \"POS_ENTROPY\",\n",
    "    \"LEXICAL_DENSITY\",\n",
    "    \"speech_rate\",\n",
    "    \"pause_ratio\",\n",
    "    \"n_pauses\",\n",
    "    \"avg_pause_duration\",\n",
    "    \"articulation_rate\",\n",
    "    \"hesitation_ratio\",\n",
    "    \"eGeMAPS_jitterLocal_sma3nz_amean\",\n",
    "    \"eGeMAPS_shimmerLocaldB_sma3nz_amean\"\n",
    "]\n",
    "\n",
    "# load filtered features\n",
    "features = load_filtered_features(\n",
    "    task_name=task_name,\n",
    "    features_dir=os.path.join(GIT_DIRECTORY, \"results/features\"),\n",
    "    selected_columns=selected_columns\n",
    ").dropna(subset=[\"Subject_ID\"])\n",
    "\n",
    "# load scores\n",
    "scores = pd.read_csv(os.path.join(GIT_DIRECTORY, \"resources/language_scores_all_subjects.csv\"))\n",
    "scores = scores[[\"Subject_ID\", target]].dropna()\n",
    "\n",
    "# keep only subjects that exist in both\n",
    "shared_ids = set(features[\"Subject_ID\"]) & set(scores[\"Subject_ID\"])\n",
    "\n",
    "X = features[features[\"Subject_ID\"].isin(shared_ids)].copy()\n",
    "y = scores[scores[\"Subject_ID\"].isin(shared_ids)].copy()\n",
    "\n",
    "# reset indices and drop ID\n",
    "X = X.sort_values(\"Subject_ID\").reset_index(drop=True).drop(columns=[\"Subject_ID\"])\n",
    "y = y.sort_values(\"Subject_ID\").reset_index(drop=True)[target]\n",
    "\n",
    "# drop rows with missing values in X, align y accordingly\n",
    "X = X.dropna()\n",
    "y = y.loc[X.index].reset_index(drop=True)\n",
    "\n",
    "# scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)\n",
    "\n",
    "# run regression\n",
    "model, metrics, X_train, X_test, y_train, y_test, y_pred_train, y_pred_test = train_and_evaluate_regression_model(\n",
    "    X_scaled, y,\n",
    "    model_class=LinearRegression,\n",
    "    model_params=None\n",
    ")\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "\n",
    "print(\"Evaluation metrics:\", metrics)"
   ],
   "id": "daa924df9f60527c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (765, 38)\n",
      "X_test shape: (192, 38)\n",
      "Evaluation metrics: {'R2': -0.0009174411008896488, 'RMSE': np.float64(4.524395189815523), 'MAE': 3.588877665037545}\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "r2_list, rmse_list, mae_list = [], [], []\n",
    "fold_predictions = []\n",
    "\n",
    "for fold, (train_index, test_index) in enumerate(kf.split(X_scaled)):\n",
    "    X_train = X_scaled.iloc[train_index]\n",
    "    X_test = X_scaled.iloc[test_index]\n",
    "    y_train = y.iloc[train_index]\n",
    "    y_test = y.iloc[test_index]\n",
    "\n",
    "    model = LinearRegression().fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Evaluate\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "\n",
    "    # Store metrics\n",
    "    r2_list.append(r2)\n",
    "    rmse_list.append(rmse)\n",
    "    mae_list.append(mae)\n",
    "\n",
    "    # Save predictions\n",
    "    fold_predictions.append(pd.DataFrame({\n",
    "        \"y_test\": y_test.values,\n",
    "        \"y_pred\": y_pred,\n",
    "        \"fold\": fold\n",
    "    }))\n",
    "\n",
    "    print(f\"Fold {fold + 1}: R² = {r2:.3f}, RMSE = {rmse:.3f}, MAE = {mae:.3f}\")"
   ],
   "id": "497a78aac41c201b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# CORRELATION MATRIX for selected features\n",
    "\n",
    "# set style\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# combine scaled features with target\n",
    "X_with_target = X_scaled.copy()\n",
    "X_with_target[target] = y.values\n",
    "\n",
    "# compute correlation matrix\n",
    "corr = X_with_target.corr()\n",
    "\n",
    "# save as CSV\n",
    "corr_csv_path = os.path.join(GIT_DIRECTORY, f\"results/regression/correlation_matrix_{task_name}_{target}_selected.csv\")\n",
    "corr.to_csv(corr_csv_path)\n",
    "print(f\"Correlation matrix saved to CSV:\\n{corr_csv_path}\")\n",
    "\n",
    "# plot heatmap\n",
    "plt.figure(figsize=(18, 16))\n",
    "sns.heatmap(\n",
    "    corr,\n",
    "    annot=False,\n",
    "    cmap=\"coolwarm\",\n",
    "    center=0,\n",
    "    square=True,\n",
    "    cbar_kws={\"shrink\": 0.8},\n",
    "    linewidths=0.5\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=90, fontsize=6)\n",
    "plt.yticks(rotation=0, fontsize=6)\n",
    "plt.title(f\"{task_name.title()} – Correlation Matrix ({target})\", fontsize=16, fontweight=\"bold\", pad=20)\n",
    "plt.tight_layout()\n",
    "\n",
    "# save plot\n",
    "plot_path = os.path.join(GIT_DIRECTORY, f\"results/plots/correlation_matrix_{task_name}_{target}_selected.png\")\n",
    "plt.savefig(plot_path, dpi=300, bbox_inches=\"tight\")\n",
    "plt.close()\n",
    "\n",
    "print(f\"Heatmap saved to:\\n{plot_path}\")"
   ],
   "id": "8522e73eb6d7cc7d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-01T18:05:46.826528Z",
     "start_time": "2025-05-01T18:05:46.786372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute feature–feature correlation matrix (excluding target)\n",
    "feature_corr = X_scaled.corr()\n",
    "\n",
    "# Mask the upper triangle to avoid duplicate pairs and self-correlation\n",
    "mask = np.triu(np.ones_like(feature_corr, dtype=bool))\n",
    "\n",
    "# Unstack the matrix to long format and drop self-pairs\n",
    "high_corr_pairs = (\n",
    "    feature_corr.where(~mask)  # apply mask\n",
    "    .stack()                   # convert to long format\n",
    "    .reset_index()             # make a DataFrame\n",
    ")\n",
    "high_corr_pairs.columns = ['Feature1', 'Feature2', 'Correlation']\n",
    "\n",
    "# Filter by threshold (e.g., > 0.7 or < -0.7)\n",
    "threshold = 0.7\n",
    "high_corr_pairs = high_corr_pairs[high_corr_pairs['Correlation'].abs() > threshold]\n",
    "\n",
    "# Sort by absolute correlation\n",
    "high_corr_pairs = high_corr_pairs.reindex(high_corr_pairs['Correlation'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "print(\"Highly intercorrelated feature pairs (|r| > 0.7):\\n\")\n",
    "print(high_corr_pairs)\n"
   ],
   "id": "c77ff85a3c2d560b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly intercorrelated feature pairs (|r| > 0.7):\n",
      "\n",
      "              Feature1           Feature2  Correlation\n",
      "626   hesitation_ratio        pause_ratio     0.998570\n",
      "22       brunets_index                ttr    -0.950396\n",
      "496           n_pauses            n_words     0.939208\n",
      "296          PRON/NOUN               PRON     0.923080\n",
      "123               INTJ  filler_word_ratio     0.918097\n",
      "338           AUX/VERB                AUX     0.837596\n",
      "275          NOUN/VERB               VERB    -0.812903\n",
      "591  articulation_rate        speech_rate     0.766562\n",
      "293          PRON/NOUN               NOUN    -0.743734\n",
      "433    LEXICAL_DENSITY        OPEN/CLOSED     0.739118\n",
      "270          NOUN/VERB               NOUN     0.732008\n",
      "395        POS_ENTROPY               NOUN    -0.730987\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
